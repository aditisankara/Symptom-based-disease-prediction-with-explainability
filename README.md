# Symptom-based-disease-prediction-with-explainability

We will utilize Clinical BERT to predict possible diseases or medical conditions based on a given list of symptoms. This functionality aims to support medical professionals in diagnosing and making informed decisions regarding potential diseases associated with specific symptoms.
We will incorporate LIME and SHAP, two explainability techniques, to provide intuitive explanations for Clinical BERT's predictions. LIME will help identify key features contributing to the model's predictions in the classification tasks, while SHAP will provide insights into the importance of each input feature for the NER task. The objective is to enhance the interpretability and transparency of Clinical BERT's decision-making process.
To prepare the dataset for training, a careful inspection was conducted, and the dependent column consisting of disease labels was converted into numerical values. Subsequently, the disease labels were transformed into a binary class matrix form, facilitating the classification task.
In order to assess the model's performance, the dataset was divided into three subsets: train, test, and validation. The transformers library, known for its powerful language models, was utilized to import and incorporate the Bio+ClinicalBERT model into the project. This particular model, which had been fine-tuned for question-type classification, proved to be suitable for the current task of symptom-based disease identification.
The next step involved tokenizing the text input, which consisted of the symptoms associated with diseases. The Bio+ClinicalBERT model efficiently transformed the raw text into a format compatible with further processing and analysis.

To enhance the model's predictive capabilities, additional layers were introduced. These layers included an input layer, a pooling layer, two fully connected layers, and a dropout layer. By integrating these layers above the existing Bio+ClinicalBERT layers and before the output layer, the model gained more flexibility and capacity to learn complex patterns from the symptom text.
For training the model, the Adam optimizer, known for its efficiency in optimizing neural networks, was employed. The balanced_accuracy metric was selected to evaluate the model's performance during the training process. The dataset was trained for a total of 2 epochs, allowing the model to learn from the available symptom-disease associations and optimize its predictions accordingly.
Once the training was completed, the team analyzed the classification report, which provided valuable insights into the model's performance on the test and validation subsets. This evaluation allowed for a deeper understanding of the model's strengths and areas for improvement.
To gain further insights into individual predictions, instances from the test set were selected and fed into the trained model. To better understand the factors influencing each prediction, the team employed the LIME (Local Interpretable Model-agnostic Explanations) explainer. LIME utilizes an interpretable model locally around each prediction and highlights the words that significantly contribute to the model's decision-making process. It assigns scores to each word in the input text, indicating their relative importance in the prediction.
